{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from utils import LRN2D\n",
    "import utils\n",
    "import glob\n",
    "import re\n",
    "import time\n",
    "from loader import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_embedding(image, model):\n",
    "    #image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_AREA) \n",
    "    image = cv2.resize(image, (96, 96)) \n",
    "    img = image[...,::-1]\n",
    "    img = np.around(np.transpose(img, (0,1,2))/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_face(face_image, input_embeddings, model):\n",
    "\n",
    "    embedding = image_to_embedding(face_image, model)\n",
    "    \n",
    "    minimum_distance = 200\n",
    "    name = None\n",
    "    \n",
    "    # Loop over  names and encodings.\n",
    "    for (input_name, input_embedding) in input_embeddings.items():\n",
    "        \n",
    "       \n",
    "        euclidean_distance = np.linalg.norm(embedding-input_embedding)\n",
    "        \n",
    "\n",
    "#         print('Euclidean distance from %s is %s' %(input_name, euclidean_distance))\n",
    "\n",
    "        \n",
    "        if euclidean_distance < minimum_distance:\n",
    "            minimum_distance = euclidean_distance\n",
    "            name = input_name\n",
    "    \n",
    "    if minimum_distance < 0.50:\n",
    "        return str(name)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_image_embeddings():\n",
    "    input_embeddings = {}\n",
    "\n",
    "    for file in glob.glob(\"images/*\"):\n",
    "        person_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        image_file = cv2.imread(file, 1)\n",
    "        input_embeddings[person_name] = image_to_embedding(image_file, model)\n",
    "\n",
    "    return input_embeddings\n",
    "\n",
    "def recognize_faces_in_cam(input_embeddings):\n",
    "    name = ''\n",
    "    cv2.namedWindow(\"Face Recognizer\")\n",
    "    vc = cv2.VideoCapture(0)\n",
    "   \n",
    "\n",
    "    font = cv2.FONT_ITALIC\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    \n",
    "    while vc.isOpened():\n",
    "        username = ''\n",
    "        _, frame = vc.read()\n",
    "        img = frame\n",
    "        height, width, channels = frame.shape\n",
    "\n",
    "        \n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        # Loop through all the faces detected \n",
    "        identities = []\n",
    "        for (x, y, w, h) in faces:\n",
    "            x1 = x\n",
    "            y1 = y\n",
    "            x2 = x+w\n",
    "            y2 = y+h\n",
    "\n",
    "           \n",
    "            \n",
    "            face_image = frame[max(0, y1):min(height, y2), max(0, x1):min(width, x2)]    \n",
    "            identity = recognize_face(face_image, input_embeddings, model)\n",
    "            \n",
    "            \n",
    "\n",
    "            if identity is not None:\n",
    "                img = cv2.rectangle(frame,(x1, y1),(x2, y2),(255,255,255),2)\n",
    "                cv2.putText(img, str(identity), (x1+5,y1-5), font, 1, (255,255,255), 2)\n",
    "                return ''.join(re.findall(r'[a-zA-Z]*',str(identity)))\n",
    "        key = cv2.waitKey(200)\n",
    "        cv2.imshow(\"Face Recognizer\", img)\n",
    "        if key == 27: # exit on ESC\n",
    "            break\n",
    "    vc.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final():\n",
    "    while True:\n",
    "        time.sleep(5)\n",
    "        input_embeddings = create_input_image_embeddings()\n",
    "        name = recognize_faces_in_cam(input_embeddings)\n",
    "        return name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
